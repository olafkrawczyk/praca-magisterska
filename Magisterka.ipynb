{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "## Ensembling two classifiers \n",
    "\n",
    "\n",
    "1. Normalizacja wsparć poszczególnych klasyfikatorów?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import load_breast_cancer, load_wine, load_digits, load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "\n",
    "def load_mammographic(): \n",
    "    columns = ['bi_rads', 'age', 'shape', 'margin', 'density', 'class']\n",
    "\n",
    "    mammographic = pd.read_csv('datasets/mammographic_masses.data', names=columns)\n",
    "    mammographic = mammographic.replace('?', np.nan)\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    dataset = pd.DataFrame(imp.fit_transform(mammographic), columns=columns)\n",
    "\n",
    "    y = dataset['class'].values.astype(int)\n",
    "    X = dataset.drop('class', axis=1).values\n",
    "    return Dataset(X, y)\n",
    "\n",
    "def load_abalone(): \n",
    "    columns = ['sex', 'len', 'dia', 'h', 'ww', 'sw', 'vw', 'shw', 'class']\n",
    "\n",
    "    dataset = pd.read_csv('datasets/abalone.data', names=columns)\n",
    "    dataset = dataset.replace('M', 0)\n",
    "    dataset = dataset.replace('F', 1)\n",
    "    dataset = dataset.replace('I', 2)\n",
    "#     mammographic = mammographic.replace('?', np.nan)\n",
    "#     imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "#     dataset = pd.DataFrame(imp.fit_transform(mammographic), columns=columns)\n",
    "\n",
    "    y = dataset['class'].values.astype(int)\n",
    "    X = dataset.drop('class', axis=1).values\n",
    "    return Dataset(X, y)\n",
    "\n",
    "def load_vihno_verde(): \n",
    "\n",
    "    dataset = pd.read_csv('datasets/winequality-white.csv', header=0, sep=';')\n",
    "#     mammographic = mammographic.replace('?', np.nan)\n",
    "#     imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "#     dataset = pd.DataFrame(imp.fit_transform(mammographic), columns=columns)\n",
    "\n",
    "    y = dataset['quality'].values.astype(int)\n",
    "    X = dataset.drop('quality', axis=1).values\n",
    "    return Dataset(X, y)\n",
    "\n",
    "\n",
    "def load_balance(): \n",
    "    columns = ['class', 'lw', 'ld', 'rw', 'rd']\n",
    "    dataset = pd.read_csv('datasets/balance-scale.data', names=columns)\n",
    "    \n",
    "    dataset = dataset.replace('L', 0)\n",
    "    dataset = dataset.replace('B', 1)\n",
    "    dataset = dataset.replace('R', 2)\n",
    "\n",
    "    y = dataset['class'].values.astype(int)\n",
    "    X = dataset.drop('class', axis=1).values\n",
    "    return Dataset(X, y)\n",
    "\n",
    "def load_yeast(): \n",
    "    columns = ['name','xz','mcg', 'gvh', 'alm', 'mit', 'erl', 'pox', 'vac', 'class']\n",
    "    dataset = pd.read_csv('datasets/yeast.data', names=columns, delim_whitespace=True)\n",
    "    dataset = dataset.drop('name', axis=1)\n",
    "    \n",
    "    dataset = dataset.replace('CYT', 0)\n",
    "    dataset = dataset.replace('NUC', 1)\n",
    "    dataset = dataset.replace('MIT', 2)\n",
    "    dataset = dataset.replace('ME3', 3)\n",
    "    dataset = dataset.replace('ME2', 4)\n",
    "    dataset = dataset.replace('ME1', 5)\n",
    "    dataset = dataset.replace('EXC', 6)\n",
    "    dataset = dataset.replace('VAC', 7)\n",
    "    dataset = dataset.replace('POX', 8)\n",
    "    dataset = dataset.replace('ERL', 9)\n",
    "\n",
    "    y = dataset['class'].values.astype(int)\n",
    "    X = dataset.drop('class', axis=1).values\n",
    "    return Dataset(X, y)\n",
    "\n",
    "def load_biodeg(): \n",
    "    columns = [x for x in range(41)]\n",
    "    columns.append('class')\n",
    "    dataset = pd.read_csv('datasets/biodeg.csv', names=columns, sep=\";\")\n",
    "    \n",
    "    dataset = dataset.replace('RB', 0)\n",
    "    dataset = dataset.replace('NRB', 1)\n",
    "\n",
    "    y = dataset['class'].values.astype(int)\n",
    "    X = dataset.drop('class', axis=1).values\n",
    "    return Dataset(X, y)\n",
    "\n",
    "def load_tic_tac(): \n",
    "    columns = [x for x in range(9)]\n",
    "    columns.append('class')\n",
    "    dataset = pd.read_csv('datasets/tic-tac-toe.data', names=columns)\n",
    "    \n",
    "    dataset = dataset.replace('x', 3)\n",
    "    dataset = dataset.replace('o', 4)\n",
    "    dataset = dataset.replace('b', 5)\n",
    "    \n",
    "    dataset = dataset.replace('negative', 0)\n",
    "    dataset = dataset.replace('positive', 1)\n",
    "    \n",
    "    y = dataset['class'].values.astype(int)\n",
    "    X = dataset.drop('class', axis=1).values\n",
    "    return Dataset(X, y)\n",
    "\n",
    "def load_segmentation(): \n",
    "    columns = ['class'] + [x for x in range(19)]\n",
    "    dataset = pd.read_csv('datasets/segmentation.test', names=columns)\n",
    "    \n",
    "    dataset = dataset.replace('BRICKFACE', 1)\n",
    "    dataset = dataset.replace('SKY', 2)\n",
    "    dataset = dataset.replace('FOLIAGE', 3)\n",
    "    dataset = dataset.replace('CEMENT', 4)\n",
    "    dataset = dataset.replace('WINDOW', 5)\n",
    "    dataset = dataset.replace('PATH', 6)\n",
    "    dataset = dataset.replace('GRASS', 7)\n",
    "    \n",
    "    y = dataset['class'].values.astype(int)\n",
    "    X = dataset.drop('class', axis=1).values\n",
    "    return Dataset(X, y)\n",
    "\n",
    "def load_phishing_websites(): \n",
    "    columns = ['id'] + [x for x in range(30)] + ['class']\n",
    "    dataset = pd.read_csv('datasets/phishing-websites.csv', names=columns)\n",
    "    \n",
    "    dataset['class'] = dataset['class'].replace(-1, 0)\n",
    "    \n",
    "    y = dataset['class'].values.astype(int)\n",
    "    X = dataset.drop('class', axis=1).values\n",
    "    return Dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_breast_cancer()\n",
    "dataset = load_phishing_websites()\n",
    "X = dataset.data\n",
    "y = dataset.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble(object):\n",
    "    \n",
    "    def __init__(self, base_classifiers):\n",
    "        self.base_classifiers = base_classifiers\n",
    "        self.meta_classifier = MLPClassifier(max_iter=1000)\n",
    "        \n",
    "    def fit_base_classfiers(self, X, y):\n",
    "        for classifier in self.base_classifiers:\n",
    "            classifier.fit(X,y)\n",
    "            \n",
    "    def fit_meta_classifier_supports(self, X, y):\n",
    "        supports = self.get_supports(X)\n",
    "        self.meta_classifier = MLPClassifier(max_iter=1000)\n",
    "        self.meta_classifier.fit(supports, y)\n",
    "        \n",
    "    def fit_meta_classifier_features(self, X, y, ):\n",
    "        supports = self.get_supports(X)\n",
    "        supports_with_features = np.concatenate((supports, X), axis=1)\n",
    "        self.meta_classifier = MLPClassifier(max_iter=10000)\n",
    "        self.meta_classifier.fit(supports_with_features, y)\n",
    "        \n",
    "    def predict_meta(self, X):\n",
    "        supports = self.get_supports(X)\n",
    "        return self.meta_classifier.predict(supports)\n",
    "\n",
    "    def predict_meta_features(self, X):\n",
    "        supports = self.get_supports(X)\n",
    "        supports = np.concatenate((supports, X), axis=1)\n",
    "        return self.meta_classifier.predict(supports)\n",
    "        \n",
    "    def get_supports(self, X):\n",
    "        temp = []\n",
    "        for classifier in self.base_classifiers:\n",
    "            if temp == []:\n",
    "                temp = classifier.predict_proba(X)\n",
    "            else:\n",
    "                temp = np.concatenate((temp, classifier.predict_proba(X)), axis=1)\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    SVC(probability=True, kernel='linear'),\n",
    "#     SVC(probability=True, kernel='rbf', gamma='auto'),\n",
    "    KNeighborsClassifier(n_neighbors=3),\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    "    MLPClassifier(max_iter=1000),\n",
    "#     MultinomialNB()\n",
    "]\n",
    "ens = Ensemble(estimators)\n",
    "\n",
    "bc_names = ['svm_lin', 'knn3', 'knn5', 'mlp']\n",
    "voting_bc = list(zip(bc_names, estimators))\n",
    "voitng_clf = VotingClassifier(voting_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['no_features', 'features', 'voting', 'svm_lin', 'knn3', 'knn5', 'mlp'])\n",
    "\n",
    "kf = StratifiedKFold(n_splits=100, random_state=5, shuffle=True)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    train_base, train_ensemble = np.split(train_index, [int(.5*len(train_index))])\n",
    "    \n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    ens.fit_base_classfiers(X_train, y_train)\n",
    "    \n",
    "    X_ens = X[train_index]\n",
    "    y_ens = y[train_index]\n",
    "    ens.fit_meta_classifier_supports(X_ens, y_ens)\n",
    "    \n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    ens_score = accuracy_score(ens.predict_meta(X_test), y_test)\n",
    "    \n",
    "    ens.fit_meta_classifier_features(X_ens, y_ens)\n",
    "    ens_score_features = accuracy_score(ens.predict_meta_features(X_test), y_test)\n",
    "    \n",
    "    voitng_clf.fit(X_train, y_train)\n",
    "    voting = accuracy_score(voitng_clf.predict(X_test), y_test)\n",
    "    \n",
    "    svm_lin = accuracy_score(ens.base_classifiers[0].predict(X_test), y_test)\n",
    "#     svm_rbf = accuracy_score(ens.base_classifiers[1].predict(X_test), y_test)\n",
    "    knn3 = accuracy_score(ens.base_classifiers[1].predict(X_test), y_test)\n",
    "    knn5 = accuracy_score(ens.base_classifiers[2].predict(X_test), y_test)\n",
    "    mlp = accuracy_score(ens.base_classifiers[3].predict(X_test), y_test)\n",
    "#     nb = accuracy_score(ens.base_classifiers[5].predict(X_test), y_test)\n",
    "    \n",
    "    \n",
    "    results.loc[len(results)] = [ens_score, ens_score_features, voting, svm_lin, knn3, knn5, mlp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in ens.base_classifiers:\n",
    "    print(accuracy_score(cls.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
