{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from mlens.ensemble import SuperLearner\n",
    "from mlens.metrics import make_scorer\n",
    "\n",
    "meta_classifier = MLPClassifier(hidden_layer_sizes=(40, 30, 10), max_iter=10000)\n",
    "accuracy_scorer = make_scorer(accuracy_score, greater_is_better=True)\n",
    "\n",
    "classifiers = [KNeighborsClassifier(n_neighbors=3),\n",
    "               KNeighborsClassifier(n_neighbors=5),\n",
    "               SVC(gamma='auto'),\n",
    "               MLPClassifier(hidden_layer_sizes=(40, 20), max_iter=10000)]\n",
    "\n",
    "classifiers_single = [KNeighborsClassifier(n_neighbors=3),\n",
    "               KNeighborsClassifier(n_neighbors=5),\n",
    "               SVC(gamma='auto'),\n",
    "               MLPClassifier(hidden_layer_sizes=(40, 20), max_iter=10000)]\n",
    "\n",
    "classifiers_names = ['KNN3', 'KNN5', 'SVC', 'MLP', 'RF', 'DecisionTree']\n",
    "\n",
    "ensemble = SuperLearner(scorer=accuracy_scorer, random_state=1075, verbose=2, folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=10,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4128, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=10, raise_on_e...y_score))],\n",
       "   n_jobs=-1, name='group-1', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=1075, sample_size=20,\n",
       "       scorer=make_scorer(accuracy_score), shuffle=False, verbose=2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.add(classifiers)\n",
    "ensemble.add_meta(meta_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x103478a50, file \"/usr...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x103478a50, file \"/usr...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    500         if self.poller is not None:\n    501             self.poller.start()\n    502         self.kernel.start()\n    503         self.io_loop = ioloop.IOLoop.current()\n    504         try:\n--> 505             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    506         except KeyboardInterrupt:\n    507             pass\n    508 \n    509 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\n/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\n/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle IOLoop._run_callback(functools.par... result=None>))>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\n/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py in _run(self=<Handle IOLoop._run_callback(functools.par... result=None>))>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method IOLoop._run_callback of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (functools.partial(<function wrap.<locals>.null_w...r at 0x1051d4e18>, <Future finished result=None>),)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/ioloop.py in _run_callback(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, callback=functools.partial(<function wrap.<locals>.null_w...r at 0x1051d4e18>, <Future finished result=None>))\n    753         \"\"\"Runs a callback with error handling.\n    754 \n    755         For use in subclasses.\n    756         \"\"\"\n    757         try:\n--> 758             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_w...r at 0x1051d4e18>, <Future finished result=None>)\n    759             if ret is not None:\n    760                 from tornado import gen\n    761                 # Functions that return Futures typically swallow all\n    762                 # exceptions and store them in the Future.  If a Future\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<Future finished result=None>,), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<Future finished result=None>,)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/gen.py in inner(f=None)\n   1228             return False\n   1229         elif not self.future.done():\n   1230             def inner(f):\n   1231                 # Break a reference cycle to speed GC.\n   1232                 f = None  # noqa\n-> 1233                 self.run()\n   1234             self.io_loop.add_future(\n   1235                 self.future, inner)\n   1236             return False\n   1237         return True\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/gen.py in run(self=<tornado.gen.Runner object>)\n   1142                         finally:\n   1143                             # Break up a reference to itself\n   1144                             # for faster GC on CPython.\n   1145                             exc_info = None\n   1146                     else:\n-> 1147                         yielded = self.gen.send(value)\n        yielded = None\n        self.gen.send = <built-in method send of generator object>\n        value = None\n   1148 \n   1149                     if stack_context._state.contexts is not orig_stack_contexts:\n   1150                         self.gen.throw(\n   1151                             stack_context.StackContextInconsistentError(\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_queue(self=<ipykernel.ipkernel.IPythonKernel object>)\n    365         \"\"\"\n    366 \n    367         while True:\n    368             # receive the next message and handle it\n    369             try:\n--> 370                 yield self.process_one()\n        self.process_one = <bound method Kernel.process_one of <ipykernel.ipkernel.IPythonKernel object>>\n    371             except Exception:\n    372                 self.log.exception(\"Error in message handler\")\n    373 \n    374     _message_counter = Any(\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>,), **kwargs={})\n    341                     # Runner). This keeps the coroutine's Runner alive.\n    342                     # We do this by exploiting the public API\n    343                     # add_done_callback() instead of putting a private\n    344                     # attribute on the Future.\n    345                     # (Github issues #1769, #2229).\n--> 346                     runner = Runner(result, future, yielded)\n        result = <generator object process_one>\n        future = <Future pending>\n        yielded = <Future finished result=(10, 4, <bound method......55cfc80>, <zmq.sugar.fr...t 0x1155cfd38>, ...]))>\n    347                     future.add_done_callback(lambda _: runner)\n    348                 yielded = None\n    349                 try:\n    350                     return future\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/gen.py in __init__(self=<tornado.gen.Runner object>, gen=None, result_future=None, first_yielded=None)\n   1075         # done so, this field will be set and must be called at the end\n   1076         # of the coroutine.\n   1077         self.stack_context_deactivate = None\n   1078         if self.handle_yield(first_yielded):\n   1079             gen = result_future = first_yielded = None\n-> 1080             self.run()\n        self.run = <bound method Runner.run of <tornado.gen.Runner object>>\n   1081 \n   1082     def register_callback(self, key):\n   1083         \"\"\"Adds ``key`` to the list of callbacks.\"\"\"\n   1084         if self.pending_callbacks is None:\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/gen.py in run(self=<tornado.gen.Runner object>)\n   1142                         finally:\n   1143                             # Break up a reference to itself\n   1144                             # for faster GC on CPython.\n   1145                             exc_info = None\n   1146                     else:\n-> 1147                         yielded = self.gen.send(value)\n        yielded = undefined\n        self.gen.send = <built-in method send of generator object>\n        value = (10, 4, <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object>>, (<zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]))\n   1148 \n   1149                     if stack_context._state.contexts is not orig_stack_contexts:\n   1150                         self.gen.throw(\n   1151                             stack_context.StackContextInconsistentError(\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py in process_one(self=<ipykernel.ipkernel.IPythonKernel object>, wait=True)\n    352         else:\n    353             try:\n    354                 priority, t, dispatch, args = self.msg_queue.get_nowait()\n    355             except QueueEmpty:\n    356                 return None\n--> 357         yield gen.maybe_future(dispatch(*args))\n        dispatch = <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object>>\n        args = (<zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    358 \n    359     @gen.coroutine\n    360     def dispatch_queue(self):\n    361         \"\"\"Coroutine to preserve order of message handling\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, <zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]), **kwargs={})\n    321                 # never actually yields, which in turn allows us to\n    322                 # use \"optional\" coroutines in critical path code without\n    323                 # performance penalty for the synchronous case.\n    324                 try:\n    325                     orig_stack_contexts = stack_context._state.contexts\n--> 326                     yielded = next(result)\n        yielded = undefined\n        result = <generator object dispatch_shell>\n    327                     if stack_context._state.contexts is not orig_stack_contexts:\n    328                         yielded = _create_future()\n    329                         yielded.set_exception(\n    330                             stack_context.StackContextInconsistentError(\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 20, 21, 2, 33, 543467, tzinfo=tzutc()), 'msg_id': 'd372ce6939c74d1086d04a218549f1f0', 'msg_type': 'execute_request', 'session': '00caa3f7e75e49048df5b6594d821542', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd372ce6939c74d1086d04a218549f1f0', 'msg_type': 'execute_request', 'parent_header': {}})\n    262             try:\n    263                 self.pre_handler_hook()\n    264             except Exception:\n    265                 self.log.debug(\"Unable to signal in pre_handler_hook:\", exc_info=True)\n    266             try:\n--> 267                 yield gen.maybe_future(handler(stream, idents, msg))\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'00caa3f7e75e49048df5b6594d821542']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 20, 21, 2, 33, 543467, tzinfo=tzutc()), 'msg_id': 'd372ce6939c74d1086d04a218549f1f0', 'msg_type': 'execute_request', 'session': '00caa3f7e75e49048df5b6594d821542', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd372ce6939c74d1086d04a218549f1f0', 'msg_type': 'execute_request', 'parent_header': {}}\n    268             except Exception:\n    269                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    270             finally:\n    271                 try:\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, <zmq.eventloop.zmqstream.ZMQStream object>, [b'00caa3f7e75e49048df5b6594d821542'], {'buffers': [], 'content': {'allow_stdin': True, 'code': 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 20, 21, 2, 33, 543467, tzinfo=tzutc()), 'msg_id': 'd372ce6939c74d1086d04a218549f1f0', 'msg_type': 'execute_request', 'session': '00caa3f7e75e49048df5b6594d821542', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd372ce6939c74d1086d04a218549f1f0', 'msg_type': 'execute_request', 'parent_header': {}}), **kwargs={})\n    321                 # never actually yields, which in turn allows us to\n    322                 # use \"optional\" coroutines in critical path code without\n    323                 # performance penalty for the synchronous case.\n    324                 try:\n    325                     orig_stack_contexts = stack_context._state.contexts\n--> 326                     yielded = next(result)\n        yielded = undefined\n        result = <generator object execute_request>\n    327                     if stack_context._state.contexts is not orig_stack_contexts:\n    328                         yielded = _create_future()\n    329                         yielded.set_exception(\n    330                             stack_context.StackContextInconsistentError(\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'00caa3f7e75e49048df5b6594d821542'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 20, 21, 2, 33, 543467, tzinfo=tzutc()), 'msg_id': 'd372ce6939c74d1086d04a218549f1f0', 'msg_type': 'execute_request', 'session': '00caa3f7e75e49048df5b6594d821542', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd372ce6939c74d1086d04a218549f1f0', 'msg_type': 'execute_request', 'parent_header': {}})\n    529             self._publish_execute_input(code, parent, self.execution_count)\n    530 \n    531         reply_content = yield gen.maybe_future(\n    532             self.do_execute(\n    533                 code, silent, store_history,\n--> 534                 user_expressions, allow_stdin,\n        user_expressions = {}\n        allow_stdin = True\n    535             )\n    536         )\n    537 \n    538         # Flush output before sending the reply.\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', False, True, {}, True), **kwargs={})\n    321                 # never actually yields, which in turn allows us to\n    322                 # use \"optional\" coroutines in critical path code without\n    323                 # performance penalty for the synchronous case.\n    324                 try:\n    325                     orig_stack_contexts = stack_context._state.contexts\n--> 326                     yielded = next(result)\n        yielded = undefined\n        result = <generator object do_execute>\n    327                     if stack_context._state.contexts is not orig_stack_contexts:\n    328                         yielded = _create_future()\n    329                         yielded.set_exception(\n    330                             stack_context.StackContextInconsistentError(\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    289                     res = yield coro_future\n    290             else:\n    291                 # runner isn't already running,\n    292                 # make synchronous call,\n    293                 # letting shell dispatch to loop runners\n--> 294                 res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        code = 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)'\n        store_history = True\n        silent = False\n    295         finally:\n    296             self._restore_input()\n    297 \n    298         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)',), **kwargs={'silent': False, 'store_history': True})\n    531             )\n    532         self.payload_manager.write_payload(payload)\n    533 \n    534     def run_cell(self, *args, **kwargs):\n    535         self._last_traceback = None\n--> 536         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)',)\n        kwargs = {'silent': False, 'store_history': True}\n    537 \n    538     def _showtraceback(self, etype, evalue, stb):\n    539         # try to preserve ordering of tracebacks and print statements\n    540         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', store_history=True, silent=False, shell_futures=True)\n   2814         result : :class:`ExecutionResult`\n   2815         \"\"\"\n   2816         result = None\n   2817         try:\n   2818             result = self._run_cell(\n-> 2819                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2820         finally:\n   2821             self.events.trigger('post_execute')\n   2822             if not silent:\n   2823                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', store_history=True, silent=False, shell_futures=True)\n   2840             runner = self.loop_runner\n   2841         else:\n   2842             runner = _pseudo_sync_runner\n   2843 \n   2844         try:\n-> 2845             return runner(coro)\n        runner = <function _pseudo_sync_runner>\n        coro = <generator object InteractiveShell.run_cell_async>\n   2846         except BaseException as e:\n   2847             info = ExecutionInfo(raw_cell, store_history, silent, shell_futures)\n   2848             result = ExecutionResult(info)\n   2849             result.error_in_exec = e\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/IPython/core/async_helpers.py in _pseudo_sync_runner(coro=<generator object InteractiveShell.run_cell_async>)\n     62 \n     63     Credit to Nathaniel Smith\n     64 \n     65     \"\"\"\n     66     try:\n---> 67         coro.send(None)\n        coro.send = <built-in method send of generator object>\n     68     except StopIteration as exc:\n     69         return exc.value\n     70     else:\n     71         # TODO: do not raise but return an execution result with the right info.\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell_async(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', store_history=True, silent=False, shell_futures=True)\n   3015                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   3016                 if _run_async:\n   3017                     interactivity = 'async'\n   3018 \n   3019                 has_raised = yield from self.run_ast_nodes(code_ast.body, cell_name,\n-> 3020                        interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   3021 \n   3022                 self.last_execution_succeeded = not has_raised\n   3023                 self.last_execution_result = result\n   3024 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>], cell_name='<ipython-input-3-5691ee16d8fa>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1051dfd30, execution_...rue silent=False shell_futures=True> result=None>)\n   3180                     return True\n   3181             else:\n   3182                 for i, node in enumerate(to_run_exec):\n   3183                     mod = ast.Module([node])\n   3184                     code = compiler(mod, cell_name, \"exec\")\n-> 3185                     if (yield from self.run_code(code, result)):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x115647810, file \"<ipython-input-3-5691ee16d8fa>\", line 5>\n        result = <ExecutionResult object at 1051dfd30, execution_...rue silent=False shell_futures=True> result=None>\n   3186                         return True\n   3187 \n   3188                 for i, node in enumerate(to_run_interactive):\n   3189                     mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x115647810, file \"<ipython-input-3-5691ee16d8fa>\", line 5>, result=<ExecutionResult object at 1051dfd30, execution_...rue silent=False shell_futures=True> result=None>, async_=False)\n   3262                 if async_:\n   3263                     last_expr = (yield from self._async_exec(code_obj, self.user_ns))\n   3264                     code = compile('last_expr', 'fake', \"single\")\n   3265                     exec(code, {'last_expr': last_expr})\n   3266                 else:\n-> 3267                     exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x115647810, file \"<ipython-input-3-5691ee16d8fa>\", line 5>\n        self.user_global_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'In': ['', 'from itertools import combinations\\n\\nfrom sklearn...y_scorer, random_state=1075, verbose=2, folds=10)', 'ensemble.add(classifiers)\\nensemble.add_meta(meta_classifier)', 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)'], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'Out': {2: SuperLearner(array_check=None, backend=None, fol...scorer(accuracy_score), shuffle=False, verbose=2)}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'SuperLearner': <class 'mlens.ensemble.super_learner.SuperLearner'>, 'X': array([[3., 0., 1., ..., 2., 1., 3.],\n       [3...., 3., 5.],\n       [0., 0., 4., ..., 2., 2., 2.]]), ...}\n        self.user_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'In': ['', 'from itertools import combinations\\n\\nfrom sklearn...y_scorer, random_state=1075, verbose=2, folds=10)', 'ensemble.add(classifiers)\\nensemble.add_meta(meta_classifier)', 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)'], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'Out': {2: SuperLearner(array_check=None, backend=None, fol...scorer(accuracy_score), shuffle=False, verbose=2)}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'SuperLearner': <class 'mlens.ensemble.super_learner.SuperLearner'>, 'X': array([[3., 0., 1., ..., 2., 1., 3.],\n       [3...., 3., 5.],\n       [0., 0., 4., ..., 2., 2., 2.]]), ...}\n   3268             finally:\n   3269                 # Reset our crash handler in place\n   3270                 sys.excepthook = old_excepthook\n   3271         except SystemExit as e:\n\n...........................................................................\n/Users/olafkrawczyk/studia/magisterka/<ipython-input-3-5691ee16d8fa> in <module>()\n      1 dataset = load_breast_cancer()\n      2 X, Y = make_multilabel_classification(n_samples=1000)\n      3 \n      4 X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=42)\n----> 5 ensemble.fit(X_train, y_train)\n      6 predictions = ensemble.predict(X_test)\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/ensemble/base.py in fit(self=SuperLearner(array_check=None, backend=None, fol...scorer(accuracy_score), shuffle=False, verbose=2), X=array([[3., 0., 2., ..., 3., 0., 1.],\n       [2...., 3., 3.],\n       [0., 1., 4., ..., 0., 4., 1.]]), y=array([[0, 0, 0, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [1, 1, 1, 0, 0],\n       [0, 0, 0, 0, 0]]), **kwargs={})\n    509             return self\n    510 \n    511         if self.model_selection:\n    512             self._id_train.fit(X)\n    513 \n--> 514         out = self._backend.fit(X, y, **kwargs)\n        out = undefined\n        self._backend.fit = <bound method Sequential.fit of Sequential(backe...nsformers=[])],\n   verbose=1)],\n      verbose=2)>\n        X = array([[3., 0., 2., ..., 3., 0., 1.],\n       [2...., 3., 3.],\n       [0., 1., 4., ..., 0., 4., 1.]])\n        y = array([[0, 0, 0, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [1, 1, 1, 0, 0],\n       [0, 0, 0, 0, 0]])\n        kwargs = {}\n    515         if out is not self._backend:\n    516             # fit_transform\n    517             return out\n    518         else:\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/ensemble/base.py in fit(self=Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2), X=array([[3., 0., 2., ..., 3., 0., 1.],\n       [2...., 3., 3.],\n       [0., 1., 4., ..., 0., 4., 1.]]), y=array([[0, 0, 0, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [1, 1, 1, 0, 0],\n       [0, 0, 0, 0, 0]]), **kwargs={})\n    153 \n    154         f, t0 = print_job(self, \"Fitting\")\n    155 \n    156         with ParallelProcessing(self.backend, self.n_jobs,\n    157                                 max(self.verbose - 4, 0)) as manager:\n--> 158             out = manager.stack(self, 'fit', X, y, **kwargs)\n        out = undefined\n        manager.stack = <bound method ParallelProcessing.stack of <mlens.parallel.backend.ParallelProcessing object>>\n        self = Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2)\n        X = array([[3., 0., 2., ..., 3., 0., 1.],\n       [2...., 3., 3.],\n       [0., 1., 4., ..., 0., 4., 1.]])\n        y = array([[0, 0, 0, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [1, 1, 1, 0, 0],\n       [0, 0, 0, 0, 0]])\n        kwargs = {}\n    159 \n    160         if self.verbose:\n    161             print_time(t0, \"{:<35}\".format(\"Fit complete\"), file=f)\n    162 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/backend.py in stack(self=<mlens.parallel.backend.ParallelProcessing object>, caller=Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2), job='fit', X=array([[3., 0., 2., ..., 3., 0., 1.],\n       [2...., 3., 3.],\n       [0., 1., 4., ..., 0., 4., 1.]]), y=array([[0, 0, 0, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [1, 1, 1, 0, 0],\n       [0, 0, 0, 0, 0]]), path=None, return_preds=False, warm_start=False, split=True, **kwargs={})\n    668             Prediction array(s).\n    669         \"\"\"\n    670         out = self.initialize(\n    671             job=job, X=X, y=y, path=path, warm_start=warm_start,\n    672             return_preds=return_preds, split=split, stack=True)\n--> 673         return self.process(caller=caller, out=out, **kwargs)\n        self.process = <bound method ParallelProcessing.process of <mlens.parallel.backend.ParallelProcessing object>>\n        caller = Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2)\n        out = {}\n        kwargs = {}\n    674 \n    675     def process(self, caller, out, **kwargs):\n    676         \"\"\"Process job.\n    677 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/backend.py in process(self=<mlens.parallel.backend.ParallelProcessing object>, caller=Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2), out=None, **kwargs={})\n    713                       backend=self.backend) as parallel:\n    714 \n    715             for task in caller:\n    716                 self.job.clear()\n    717 \n--> 718                 self._partial_process(task, parallel, **kwargs)\n        self._partial_process = <bound method ParallelProcessing._partial_proces...lens.parallel.backend.ParallelProcessing object>>\n        task = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=1)\n        parallel = Parallel(n_jobs=-1)\n        kwargs = {}\n    719 \n    720                 if task.name in return_names:\n    721                     out.append(self.get_preds(dtype=_dtype(task)))\n    722 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/backend.py in _partial_process(self=<mlens.parallel.backend.ParallelProcessing object>, task=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=1), parallel=Parallel(n_jobs=-1), **kwargs={})\n    734         task.setup(self.job.predict_in, self.job.targets, self.job.job)\n    735 \n    736         if not task.__no_output__:\n    737             self._gen_prediction_array(task, self.job.job, self.__threading__)\n    738 \n--> 739         task(self.job.args(**kwargs), parallel=parallel)\n        task = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=1)\n        self.job.args = <bound method Job.args of <mlens.parallel.backend.Job object>>\n        kwargs = {}\n        parallel = Parallel(n_jobs=-1)\n    740 \n    741         if not task.__no_output__ and getattr(task, 'n_feature_prop', 0):\n    742             self._propagate_features(task)\n    743 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/layer.py in __call__(self=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=1), args={'auxiliary': {'P': None, 'X': array([[3., 0., 2., ..., 3., 0., 1.],\n       [2...., 3., 3.],\n       [0., 1., 4., ..., 0., 4., 1.]]), 'y': array([[0, 0, 0, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [1, 1, 1, 0, 0],\n       [0, 0, 0, 0, 0]])}, 'dir': [('kneighborsclassifier-1.0.0', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': array([[0., 0., 0., 0.],\n       [0., 0., 0., 0.]...0., 0.],\n       [0., 0., 0., 0.]], dtype=float32), 'X': array([[3., 0., 2., ..., 3., 0., 1.],\n       [2...., 3., 3.],\n       [0., 1., 4., ..., 0., 4., 1.]]), 'y': array([[0, 0, 0, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [1, 1, 1, 0, 0],\n       [0, 0, 0, 0, 0]])}}, parallel=Parallel(n_jobs=-1))\n    147         if self.verbose >= 2:\n    148             safe_print(msg.format('Learners ...'), file=f, end=e2)\n    149             t1 = time()\n    150 \n    151         parallel(delayed(sublearner, not _threading)()\n--> 152                  for learner in self.learners\n        self.learners = [Learner(attr='predict', backend='threading', dty...ception=True, scorer=make_scorer(accuracy_score)), Learner(attr='predict', backend='threading', dty...ception=True, scorer=make_scorer(accuracy_score)), Learner(attr='predict', backend='threading', dty...ception=True, scorer=make_scorer(accuracy_score)), Learner(attr='predict', backend='threading', dty...ception=True, scorer=make_scorer(accuracy_score))]\n    153                  for sublearner in learner(args, 'main'))\n    154 \n    155         if self.verbose >= 2:\n    156             print_time(t1, 'done', file=f)\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object Layer.__call__.<locals>.<genexpr>>)\n    788             if pre_dispatch == \"all\" or n_jobs == 1:\n    789                 # The iterable was consumed all at once by the above for loop.\n    790                 # No need to wait for async callbacks to trigger to\n    791                 # consumption.\n    792                 self._iterating = False\n--> 793             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    794             # Make sure that we get a last message telling us we are done\n    795             elapsed_time = time.time() - self._start_time\n    796             self._print('Done %3i out of %3i | elapsed: %s finished',\n    797                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Jan 20 22:02:34 2019\nPID: 11053                Python 3.6.5: /usr/local/opt/python/bin/python3.6\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.SubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.SubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/learner.py in __call__(self=<mlens.parallel.learner.SubLearner object>)\n    119         else:\n    120             self.processing_index = ''\n    121 \n    122     def __call__(self):\n    123         \"\"\"Launch job\"\"\"\n--> 124         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.SubLearner object>\n        self.job = 'fit'\n    125 \n    126     def fit(self, path=None):\n    127         \"\"\"Fit sub-learner\"\"\"\n    128         if path is None:\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/learner.py in fit(self=<mlens.parallel.learner.SubLearner object>, path=[('kneighborsclassifier-1.0.0', <mlens.parallel.learner.IndexedEstimator object>)])\n    131         transformers = self._load_preprocess(path)\n    132 \n    133         self._fit(transformers)\n    134 \n    135         if self.out_array is not None:\n--> 136             self._predict(transformers, self.scorer is not None)\n        self._predict = <bound method SubLearner._predict of <mlens.parallel.learner.SubLearner object>>\n        transformers = None\n        self.scorer = make_scorer(accuracy_score)\n    137 \n    138         o = IndexedEstimator(estimator=self.estimator,\n    139                              name=self.name_index,\n    140                              index=self.index,\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/learner.py in _predict(self=<mlens.parallel.learner.SubLearner object>, transformers=None, score_preds=True)\n    200 \n    201         self.pred_time_ = time() - t0\n    202 \n    203         # Assign predictions to matrix\n    204         assign_predictions(self.out_array, predictions,\n--> 205                            self.out_index, self.output_columns, n)\n        self.out_index = (0, 50)\n        self.output_columns = 0\n        n = 500\n    206 \n    207         # Score predictions if applicable\n    208         if score_preds:\n    209             self.score_ = score_predictions(\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/_base_functions.py in assign_predictions(pred=array([[0., 0., 0., 0.],\n       [0., 0., 0., 0.]...0., 0.],\n       [0., 0., 0., 0.]], dtype=float32), p=array([[1, 1, 1, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [0, 0, 1, 1, 0],\n       [1, 0, 0, 0, 1]]), tei=(0, 50), col=0, n=500)\n    210             idx = slice(tei[0] - r, tei[1] - r)\n    211 \n    212         if len(p.shape) == 1:\n    213             pred[idx, col] = p\n    214         else:\n--> 215             pred[(idx, slice(col, col + p.shape[1]))] = p\n        pred = array([[0., 0., 0., 0.],\n       [0., 0., 0., 0.]...0., 0.],\n       [0., 0., 0., 0.]], dtype=float32)\n        idx = slice(0, 50, None)\n        col = 0\n        p.shape = (50, 5)\n        p = array([[1, 1, 1, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [0, 0, 1, 1, 0],\n       [1, 0, 0, 0, 1]])\n    216 \n    217 \n    218 def score_predictions(y, p, scorer, name, inst_name):\n    219     \"\"\"Try-Except wrapper around Learner scoring\"\"\"\n\nValueError: could not broadcast input array from shape (50,5) into shape (50,4)\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mlens/parallel/learner.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;34m\"\"\"Launch job\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mlens/parallel/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_array\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mlens/parallel/learner.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, transformers, score_preds)\u001b[0m\n\u001b[1;32m    204\u001b[0m         assign_predictions(self.out_array, predictions,\n\u001b[0;32m--> 205\u001b[0;31m                            self.out_index, self.output_columns, n)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mlens/parallel/_base_functions.py\u001b[0m in \u001b[0;36massign_predictions\u001b[0;34m(pred, p, tei, col, n)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (50,5) into shape (50,4)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mlens/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sun Jan 20 22:02:34 2019\nPID: 11053                Python 3.6.5: /usr/local/opt/python/bin/python3.6\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.SubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.SubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/learner.py in __call__(self=<mlens.parallel.learner.SubLearner object>)\n    119         else:\n    120             self.processing_index = ''\n    121 \n    122     def __call__(self):\n    123         \"\"\"Launch job\"\"\"\n--> 124         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.SubLearner object>\n        self.job = 'fit'\n    125 \n    126     def fit(self, path=None):\n    127         \"\"\"Fit sub-learner\"\"\"\n    128         if path is None:\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/learner.py in fit(self=<mlens.parallel.learner.SubLearner object>, path=[('kneighborsclassifier-1.0.0', <mlens.parallel.learner.IndexedEstimator object>)])\n    131         transformers = self._load_preprocess(path)\n    132 \n    133         self._fit(transformers)\n    134 \n    135         if self.out_array is not None:\n--> 136             self._predict(transformers, self.scorer is not None)\n        self._predict = <bound method SubLearner._predict of <mlens.parallel.learner.SubLearner object>>\n        transformers = None\n        self.scorer = make_scorer(accuracy_score)\n    137 \n    138         o = IndexedEstimator(estimator=self.estimator,\n    139                              name=self.name_index,\n    140                              index=self.index,\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/learner.py in _predict(self=<mlens.parallel.learner.SubLearner object>, transformers=None, score_preds=True)\n    200 \n    201         self.pred_time_ = time() - t0\n    202 \n    203         # Assign predictions to matrix\n    204         assign_predictions(self.out_array, predictions,\n--> 205                            self.out_index, self.output_columns, n)\n        self.out_index = (0, 50)\n        self.output_columns = 0\n        n = 500\n    206 \n    207         # Score predictions if applicable\n    208         if score_preds:\n    209             self.score_ = score_predictions(\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/_base_functions.py in assign_predictions(pred=array([[0., 0., 0., 0.],\n       [0., 0., 0., 0.]...0., 0.],\n       [0., 0., 0., 0.]], dtype=float32), p=array([[1, 1, 1, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [0, 0, 1, 1, 0],\n       [1, 0, 0, 0, 1]]), tei=(0, 50), col=0, n=500)\n    210             idx = slice(tei[0] - r, tei[1] - r)\n    211 \n    212         if len(p.shape) == 1:\n    213             pred[idx, col] = p\n    214         else:\n--> 215             pred[(idx, slice(col, col + p.shape[1]))] = p\n        pred = array([[0., 0., 0., 0.],\n       [0., 0., 0., 0.]...0., 0.],\n       [0., 0., 0., 0.]], dtype=float32)\n        idx = slice(0, 50, None)\n        col = 0\n        p.shape = (50, 5)\n        p = array([[1, 1, 1, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [0, 0, 1, 1, 0],\n       [1, 0, 0, 0, 1]])\n    216 \n    217 \n    218 def score_predictions(y, p, scorer, name, inst_name):\n    219     \"\"\"Try-Except wrapper around Learner scoring\"\"\"\n\nValueError: could not broadcast input array from shape (50,5) into shape (50,4)\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5691ee16d8fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;31m# fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m         with ParallelProcessing(self.backend, self.n_jobs,\n\u001b[1;32m    157\u001b[0m                                 max(self.verbose - 4, 0)) as manager:\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mlens/parallel/backend.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(self, caller, job, X, y, path, return_preds, warm_start, split, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0mjob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             return_preds=return_preds, split=split, stack=True)\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaller\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mlens/parallel/backend.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, caller, out, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_partial_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreturn_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mlens/parallel/backend.py\u001b[0m in \u001b[0;36m_partial_process\u001b[0;34m(self, task, parallel, **kwargs)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen_prediction_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__threading__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0mtask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__no_output__\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_feature_prop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mlens/parallel/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, args, parallel)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         parallel(delayed(sublearner, not _threading)()\n\u001b[0;32m--> 152\u001b[0;31m                  \u001b[0;32mfor\u001b[0m \u001b[0mlearner\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearners\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                  for sublearner in learner(args, 'main'))\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x103478a50, file \"/usr...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x103478a50, file \"/usr...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    500         if self.poller is not None:\n    501             self.poller.start()\n    502         self.kernel.start()\n    503         self.io_loop = ioloop.IOLoop.current()\n    504         try:\n--> 505             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    506         except KeyboardInterrupt:\n    507             pass\n    508 \n    509 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\n/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\n/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle IOLoop._run_callback(functools.par... result=None>))>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\n/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py in _run(self=<Handle IOLoop._run_callback(functools.par... result=None>))>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method IOLoop._run_callback of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (functools.partial(<function wrap.<locals>.null_w...r at 0x1051d4e18>, <Future finished result=None>),)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/ioloop.py in _run_callback(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, callback=functools.partial(<function wrap.<locals>.null_w...r at 0x1051d4e18>, <Future finished result=None>))\n    753         \"\"\"Runs a callback with error handling.\n    754 \n    755         For use in subclasses.\n    756         \"\"\"\n    757         try:\n--> 758             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_w...r at 0x1051d4e18>, <Future finished result=None>)\n    759             if ret is not None:\n    760                 from tornado import gen\n    761                 # Functions that return Futures typically swallow all\n    762                 # exceptions and store them in the Future.  If a Future\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<Future finished result=None>,), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<Future finished result=None>,)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/gen.py in inner(f=None)\n   1228             return False\n   1229         elif not self.future.done():\n   1230             def inner(f):\n   1231                 # Break a reference cycle to speed GC.\n   1232                 f = None  # noqa\n-> 1233                 self.run()\n   1234             self.io_loop.add_future(\n   1235                 self.future, inner)\n   1236             return False\n   1237         return True\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/gen.py in run(self=<tornado.gen.Runner object>)\n   1142                         finally:\n   1143                             # Break up a reference to itself\n   1144                             # for faster GC on CPython.\n   1145                             exc_info = None\n   1146                     else:\n-> 1147                         yielded = self.gen.send(value)\n        yielded = None\n        self.gen.send = <built-in method send of generator object>\n        value = None\n   1148 \n   1149                     if stack_context._state.contexts is not orig_stack_contexts:\n   1150                         self.gen.throw(\n   1151                             stack_context.StackContextInconsistentError(\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_queue(self=<ipykernel.ipkernel.IPythonKernel object>)\n    365         \"\"\"\n    366 \n    367         while True:\n    368             # receive the next message and handle it\n    369             try:\n--> 370                 yield self.process_one()\n        self.process_one = <bound method Kernel.process_one of <ipykernel.ipkernel.IPythonKernel object>>\n    371             except Exception:\n    372                 self.log.exception(\"Error in message handler\")\n    373 \n    374     _message_counter = Any(\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>,), **kwargs={})\n    341                     # Runner). This keeps the coroutine's Runner alive.\n    342                     # We do this by exploiting the public API\n    343                     # add_done_callback() instead of putting a private\n    344                     # attribute on the Future.\n    345                     # (Github issues #1769, #2229).\n--> 346                     runner = Runner(result, future, yielded)\n        result = <generator object process_one>\n        future = <Future pending>\n        yielded = <Future finished result=(10, 4, <bound method......55cfc80>, <zmq.sugar.fr...t 0x1155cfd38>, ...]))>\n    347                     future.add_done_callback(lambda _: runner)\n    348                 yielded = None\n    349                 try:\n    350                     return future\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/gen.py in __init__(self=<tornado.gen.Runner object>, gen=None, result_future=None, first_yielded=None)\n   1075         # done so, this field will be set and must be called at the end\n   1076         # of the coroutine.\n   1077         self.stack_context_deactivate = None\n   1078         if self.handle_yield(first_yielded):\n   1079             gen = result_future = first_yielded = None\n-> 1080             self.run()\n        self.run = <bound method Runner.run of <tornado.gen.Runner object>>\n   1081 \n   1082     def register_callback(self, key):\n   1083         \"\"\"Adds ``key`` to the list of callbacks.\"\"\"\n   1084         if self.pending_callbacks is None:\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/gen.py in run(self=<tornado.gen.Runner object>)\n   1142                         finally:\n   1143                             # Break up a reference to itself\n   1144                             # for faster GC on CPython.\n   1145                             exc_info = None\n   1146                     else:\n-> 1147                         yielded = self.gen.send(value)\n        yielded = undefined\n        self.gen.send = <built-in method send of generator object>\n        value = (10, 4, <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object>>, (<zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]))\n   1148 \n   1149                     if stack_context._state.contexts is not orig_stack_contexts:\n   1150                         self.gen.throw(\n   1151                             stack_context.StackContextInconsistentError(\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py in process_one(self=<ipykernel.ipkernel.IPythonKernel object>, wait=True)\n    352         else:\n    353             try:\n    354                 priority, t, dispatch, args = self.msg_queue.get_nowait()\n    355             except QueueEmpty:\n    356                 return None\n--> 357         yield gen.maybe_future(dispatch(*args))\n        dispatch = <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object>>\n        args = (<zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    358 \n    359     @gen.coroutine\n    360     def dispatch_queue(self):\n    361         \"\"\"Coroutine to preserve order of message handling\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, <zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]), **kwargs={})\n    321                 # never actually yields, which in turn allows us to\n    322                 # use \"optional\" coroutines in critical path code without\n    323                 # performance penalty for the synchronous case.\n    324                 try:\n    325                     orig_stack_contexts = stack_context._state.contexts\n--> 326                     yielded = next(result)\n        yielded = undefined\n        result = <generator object dispatch_shell>\n    327                     if stack_context._state.contexts is not orig_stack_contexts:\n    328                         yielded = _create_future()\n    329                         yielded.set_exception(\n    330                             stack_context.StackContextInconsistentError(\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 20, 21, 2, 33, 543467, tzinfo=tzutc()), 'msg_id': 'd372ce6939c74d1086d04a218549f1f0', 'msg_type': 'execute_request', 'session': '00caa3f7e75e49048df5b6594d821542', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd372ce6939c74d1086d04a218549f1f0', 'msg_type': 'execute_request', 'parent_header': {}})\n    262             try:\n    263                 self.pre_handler_hook()\n    264             except Exception:\n    265                 self.log.debug(\"Unable to signal in pre_handler_hook:\", exc_info=True)\n    266             try:\n--> 267                 yield gen.maybe_future(handler(stream, idents, msg))\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'00caa3f7e75e49048df5b6594d821542']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 20, 21, 2, 33, 543467, tzinfo=tzutc()), 'msg_id': 'd372ce6939c74d1086d04a218549f1f0', 'msg_type': 'execute_request', 'session': '00caa3f7e75e49048df5b6594d821542', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd372ce6939c74d1086d04a218549f1f0', 'msg_type': 'execute_request', 'parent_header': {}}\n    268             except Exception:\n    269                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    270             finally:\n    271                 try:\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, <zmq.eventloop.zmqstream.ZMQStream object>, [b'00caa3f7e75e49048df5b6594d821542'], {'buffers': [], 'content': {'allow_stdin': True, 'code': 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 20, 21, 2, 33, 543467, tzinfo=tzutc()), 'msg_id': 'd372ce6939c74d1086d04a218549f1f0', 'msg_type': 'execute_request', 'session': '00caa3f7e75e49048df5b6594d821542', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd372ce6939c74d1086d04a218549f1f0', 'msg_type': 'execute_request', 'parent_header': {}}), **kwargs={})\n    321                 # never actually yields, which in turn allows us to\n    322                 # use \"optional\" coroutines in critical path code without\n    323                 # performance penalty for the synchronous case.\n    324                 try:\n    325                     orig_stack_contexts = stack_context._state.contexts\n--> 326                     yielded = next(result)\n        yielded = undefined\n        result = <generator object execute_request>\n    327                     if stack_context._state.contexts is not orig_stack_contexts:\n    328                         yielded = _create_future()\n    329                         yielded.set_exception(\n    330                             stack_context.StackContextInconsistentError(\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'00caa3f7e75e49048df5b6594d821542'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 20, 21, 2, 33, 543467, tzinfo=tzutc()), 'msg_id': 'd372ce6939c74d1086d04a218549f1f0', 'msg_type': 'execute_request', 'session': '00caa3f7e75e49048df5b6594d821542', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd372ce6939c74d1086d04a218549f1f0', 'msg_type': 'execute_request', 'parent_header': {}})\n    529             self._publish_execute_input(code, parent, self.execution_count)\n    530 \n    531         reply_content = yield gen.maybe_future(\n    532             self.do_execute(\n    533                 code, silent, store_history,\n--> 534                 user_expressions, allow_stdin,\n        user_expressions = {}\n        allow_stdin = True\n    535             )\n    536         )\n    537 \n    538         # Flush output before sending the reply.\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/tornado/gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', False, True, {}, True), **kwargs={})\n    321                 # never actually yields, which in turn allows us to\n    322                 # use \"optional\" coroutines in critical path code without\n    323                 # performance penalty for the synchronous case.\n    324                 try:\n    325                     orig_stack_contexts = stack_context._state.contexts\n--> 326                     yielded = next(result)\n        yielded = undefined\n        result = <generator object do_execute>\n    327                     if stack_context._state.contexts is not orig_stack_contexts:\n    328                         yielded = _create_future()\n    329                         yielded.set_exception(\n    330                             stack_context.StackContextInconsistentError(\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    289                     res = yield coro_future\n    290             else:\n    291                 # runner isn't already running,\n    292                 # make synchronous call,\n    293                 # letting shell dispatch to loop runners\n--> 294                 res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        code = 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)'\n        store_history = True\n        silent = False\n    295         finally:\n    296             self._restore_input()\n    297 \n    298         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)',), **kwargs={'silent': False, 'store_history': True})\n    531             )\n    532         self.payload_manager.write_payload(payload)\n    533 \n    534     def run_cell(self, *args, **kwargs):\n    535         self._last_traceback = None\n--> 536         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)',)\n        kwargs = {'silent': False, 'store_history': True}\n    537 \n    538     def _showtraceback(self, etype, evalue, stb):\n    539         # try to preserve ordering of tracebacks and print statements\n    540         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', store_history=True, silent=False, shell_futures=True)\n   2814         result : :class:`ExecutionResult`\n   2815         \"\"\"\n   2816         result = None\n   2817         try:\n   2818             result = self._run_cell(\n-> 2819                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2820         finally:\n   2821             self.events.trigger('post_execute')\n   2822             if not silent:\n   2823                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', store_history=True, silent=False, shell_futures=True)\n   2840             runner = self.loop_runner\n   2841         else:\n   2842             runner = _pseudo_sync_runner\n   2843 \n   2844         try:\n-> 2845             return runner(coro)\n        runner = <function _pseudo_sync_runner>\n        coro = <generator object InteractiveShell.run_cell_async>\n   2846         except BaseException as e:\n   2847             info = ExecutionInfo(raw_cell, store_history, silent, shell_futures)\n   2848             result = ExecutionResult(info)\n   2849             result.error_in_exec = e\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/IPython/core/async_helpers.py in _pseudo_sync_runner(coro=<generator object InteractiveShell.run_cell_async>)\n     62 \n     63     Credit to Nathaniel Smith\n     64 \n     65     \"\"\"\n     66     try:\n---> 67         coro.send(None)\n        coro.send = <built-in method send of generator object>\n     68     except StopIteration as exc:\n     69         return exc.value\n     70     else:\n     71         # TODO: do not raise but return an execution result with the right info.\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell_async(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)', store_history=True, silent=False, shell_futures=True)\n   3015                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   3016                 if _run_async:\n   3017                     interactivity = 'async'\n   3018 \n   3019                 has_raised = yield from self.run_ast_nodes(code_ast.body, cell_name,\n-> 3020                        interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   3021 \n   3022                 self.last_execution_succeeded = not has_raised\n   3023                 self.last_execution_result = result\n   3024 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>], cell_name='<ipython-input-3-5691ee16d8fa>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1051dfd30, execution_...rue silent=False shell_futures=True> result=None>)\n   3180                     return True\n   3181             else:\n   3182                 for i, node in enumerate(to_run_exec):\n   3183                     mod = ast.Module([node])\n   3184                     code = compiler(mod, cell_name, \"exec\")\n-> 3185                     if (yield from self.run_code(code, result)):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x115647810, file \"<ipython-input-3-5691ee16d8fa>\", line 5>\n        result = <ExecutionResult object at 1051dfd30, execution_...rue silent=False shell_futures=True> result=None>\n   3186                         return True\n   3187 \n   3188                 for i, node in enumerate(to_run_interactive):\n   3189                     mod = ast.Interactive([node])\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x115647810, file \"<ipython-input-3-5691ee16d8fa>\", line 5>, result=<ExecutionResult object at 1051dfd30, execution_...rue silent=False shell_futures=True> result=None>, async_=False)\n   3262                 if async_:\n   3263                     last_expr = (yield from self._async_exec(code_obj, self.user_ns))\n   3264                     code = compile('last_expr', 'fake', \"single\")\n   3265                     exec(code, {'last_expr': last_expr})\n   3266                 else:\n-> 3267                     exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x115647810, file \"<ipython-input-3-5691ee16d8fa>\", line 5>\n        self.user_global_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'In': ['', 'from itertools import combinations\\n\\nfrom sklearn...y_scorer, random_state=1075, verbose=2, folds=10)', 'ensemble.add(classifiers)\\nensemble.add_meta(meta_classifier)', 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)'], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'Out': {2: SuperLearner(array_check=None, backend=None, fol...scorer(accuracy_score), shuffle=False, verbose=2)}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'SuperLearner': <class 'mlens.ensemble.super_learner.SuperLearner'>, 'X': array([[3., 0., 1., ..., 2., 1., 3.],\n       [3...., 3., 5.],\n       [0., 0., 4., ..., 2., 2., 2.]]), ...}\n        self.user_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'In': ['', 'from itertools import combinations\\n\\nfrom sklearn...y_scorer, random_state=1075, verbose=2, folds=10)', 'ensemble.add(classifiers)\\nensemble.add_meta(meta_classifier)', 'dataset = load_breast_cancer()\\nX, Y = make_multi..., y_train)\\npredictions = ensemble.predict(X_test)'], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'Out': {2: SuperLearner(array_check=None, backend=None, fol...scorer(accuracy_score), shuffle=False, verbose=2)}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'SuperLearner': <class 'mlens.ensemble.super_learner.SuperLearner'>, 'X': array([[3., 0., 1., ..., 2., 1., 3.],\n       [3...., 3., 5.],\n       [0., 0., 4., ..., 2., 2., 2.]]), ...}\n   3268             finally:\n   3269                 # Reset our crash handler in place\n   3270                 sys.excepthook = old_excepthook\n   3271         except SystemExit as e:\n\n...........................................................................\n/Users/olafkrawczyk/studia/magisterka/<ipython-input-3-5691ee16d8fa> in <module>()\n      1 dataset = load_breast_cancer()\n      2 X, Y = make_multilabel_classification(n_samples=1000)\n      3 \n      4 X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=42)\n----> 5 ensemble.fit(X_train, y_train)\n      6 predictions = ensemble.predict(X_test)\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/ensemble/base.py in fit(self=SuperLearner(array_check=None, backend=None, fol...scorer(accuracy_score), shuffle=False, verbose=2), X=array([[3., 0., 2., ..., 3., 0., 1.],\n       [2...., 3., 3.],\n       [0., 1., 4., ..., 0., 4., 1.]]), y=array([[0, 0, 0, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [1, 1, 1, 0, 0],\n       [0, 0, 0, 0, 0]]), **kwargs={})\n    509             return self\n    510 \n    511         if self.model_selection:\n    512             self._id_train.fit(X)\n    513 \n--> 514         out = self._backend.fit(X, y, **kwargs)\n        out = undefined\n        self._backend.fit = <bound method Sequential.fit of Sequential(backe...nsformers=[])],\n   verbose=1)],\n      verbose=2)>\n        X = array([[3., 0., 2., ..., 3., 0., 1.],\n       [2...., 3., 3.],\n       [0., 1., 4., ..., 0., 4., 1.]])\n        y = array([[0, 0, 0, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [1, 1, 1, 0, 0],\n       [0, 0, 0, 0, 0]])\n        kwargs = {}\n    515         if out is not self._backend:\n    516             # fit_transform\n    517             return out\n    518         else:\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/ensemble/base.py in fit(self=Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2), X=array([[3., 0., 2., ..., 3., 0., 1.],\n       [2...., 3., 3.],\n       [0., 1., 4., ..., 0., 4., 1.]]), y=array([[0, 0, 0, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [1, 1, 1, 0, 0],\n       [0, 0, 0, 0, 0]]), **kwargs={})\n    153 \n    154         f, t0 = print_job(self, \"Fitting\")\n    155 \n    156         with ParallelProcessing(self.backend, self.n_jobs,\n    157                                 max(self.verbose - 4, 0)) as manager:\n--> 158             out = manager.stack(self, 'fit', X, y, **kwargs)\n        out = undefined\n        manager.stack = <bound method ParallelProcessing.stack of <mlens.parallel.backend.ParallelProcessing object>>\n        self = Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2)\n        X = array([[3., 0., 2., ..., 3., 0., 1.],\n       [2...., 3., 3.],\n       [0., 1., 4., ..., 0., 4., 1.]])\n        y = array([[0, 0, 0, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [1, 1, 1, 0, 0],\n       [0, 0, 0, 0, 0]])\n        kwargs = {}\n    159 \n    160         if self.verbose:\n    161             print_time(t0, \"{:<35}\".format(\"Fit complete\"), file=f)\n    162 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/backend.py in stack(self=<mlens.parallel.backend.ParallelProcessing object>, caller=Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2), job='fit', X=array([[3., 0., 2., ..., 3., 0., 1.],\n       [2...., 3., 3.],\n       [0., 1., 4., ..., 0., 4., 1.]]), y=array([[0, 0, 0, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [1, 1, 1, 0, 0],\n       [0, 0, 0, 0, 0]]), path=None, return_preds=False, warm_start=False, split=True, **kwargs={})\n    668             Prediction array(s).\n    669         \"\"\"\n    670         out = self.initialize(\n    671             job=job, X=X, y=y, path=path, warm_start=warm_start,\n    672             return_preds=return_preds, split=split, stack=True)\n--> 673         return self.process(caller=caller, out=out, **kwargs)\n        self.process = <bound method ParallelProcessing.process of <mlens.parallel.backend.ParallelProcessing object>>\n        caller = Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2)\n        out = {}\n        kwargs = {}\n    674 \n    675     def process(self, caller, out, **kwargs):\n    676         \"\"\"Process job.\n    677 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/backend.py in process(self=<mlens.parallel.backend.ParallelProcessing object>, caller=Sequential(backend='threading', dtype=<class 'nu...ansformers=[])],\n   verbose=1)],\n      verbose=2), out=None, **kwargs={})\n    713                       backend=self.backend) as parallel:\n    714 \n    715             for task in caller:\n    716                 self.job.clear()\n    717 \n--> 718                 self._partial_process(task, parallel, **kwargs)\n        self._partial_process = <bound method ParallelProcessing._partial_proces...lens.parallel.backend.ParallelProcessing object>>\n        task = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=1)\n        parallel = Parallel(n_jobs=-1)\n        kwargs = {}\n    719 \n    720                 if task.name in return_names:\n    721                     out.append(self.get_preds(dtype=_dtype(task)))\n    722 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/backend.py in _partial_process(self=<mlens.parallel.backend.ParallelProcessing object>, task=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=1), parallel=Parallel(n_jobs=-1), **kwargs={})\n    734         task.setup(self.job.predict_in, self.job.targets, self.job.job)\n    735 \n    736         if not task.__no_output__:\n    737             self._gen_prediction_array(task, self.job.job, self.__threading__)\n    738 \n--> 739         task(self.job.args(**kwargs), parallel=parallel)\n        task = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=1)\n        self.job.args = <bound method Job.args of <mlens.parallel.backend.Job object>>\n        kwargs = {}\n        parallel = Parallel(n_jobs=-1)\n    740 \n    741         if not task.__no_output__ and getattr(task, 'n_feature_prop', 0):\n    742             self._propagate_features(task)\n    743 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/layer.py in __call__(self=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=1), args={'auxiliary': {'P': None, 'X': array([[3., 0., 2., ..., 3., 0., 1.],\n       [2...., 3., 3.],\n       [0., 1., 4., ..., 0., 4., 1.]]), 'y': array([[0, 0, 0, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [1, 1, 1, 0, 0],\n       [0, 0, 0, 0, 0]])}, 'dir': [('kneighborsclassifier-1.0.0', <mlens.parallel.learner.IndexedEstimator object>)], 'job': 'fit', 'main': {'P': array([[0., 0., 0., 0.],\n       [0., 0., 0., 0.]...0., 0.],\n       [0., 0., 0., 0.]], dtype=float32), 'X': array([[3., 0., 2., ..., 3., 0., 1.],\n       [2...., 3., 3.],\n       [0., 1., 4., ..., 0., 4., 1.]]), 'y': array([[0, 0, 0, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [1, 1, 1, 0, 0],\n       [0, 0, 0, 0, 0]])}}, parallel=Parallel(n_jobs=-1))\n    147         if self.verbose >= 2:\n    148             safe_print(msg.format('Learners ...'), file=f, end=e2)\n    149             t1 = time()\n    150 \n    151         parallel(delayed(sublearner, not _threading)()\n--> 152                  for learner in self.learners\n        self.learners = [Learner(attr='predict', backend='threading', dty...ception=True, scorer=make_scorer(accuracy_score)), Learner(attr='predict', backend='threading', dty...ception=True, scorer=make_scorer(accuracy_score)), Learner(attr='predict', backend='threading', dty...ception=True, scorer=make_scorer(accuracy_score)), Learner(attr='predict', backend='threading', dty...ception=True, scorer=make_scorer(accuracy_score))]\n    153                  for sublearner in learner(args, 'main'))\n    154 \n    155         if self.verbose >= 2:\n    156             print_time(t1, 'done', file=f)\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object Layer.__call__.<locals>.<genexpr>>)\n    788             if pre_dispatch == \"all\" or n_jobs == 1:\n    789                 # The iterable was consumed all at once by the above for loop.\n    790                 # No need to wait for async callbacks to trigger to\n    791                 # consumption.\n    792                 self._iterating = False\n--> 793             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    794             # Make sure that we get a last message telling us we are done\n    795             elapsed_time = time.time() - self._start_time\n    796             self._print('Done %3i out of %3i | elapsed: %s finished',\n    797                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Jan 20 22:02:34 2019\nPID: 11053                Python 3.6.5: /usr/local/opt/python/bin/python3.6\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.SubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.SubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/learner.py in __call__(self=<mlens.parallel.learner.SubLearner object>)\n    119         else:\n    120             self.processing_index = ''\n    121 \n    122     def __call__(self):\n    123         \"\"\"Launch job\"\"\"\n--> 124         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.SubLearner object>\n        self.job = 'fit'\n    125 \n    126     def fit(self, path=None):\n    127         \"\"\"Fit sub-learner\"\"\"\n    128         if path is None:\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/learner.py in fit(self=<mlens.parallel.learner.SubLearner object>, path=[('kneighborsclassifier-1.0.0', <mlens.parallel.learner.IndexedEstimator object>)])\n    131         transformers = self._load_preprocess(path)\n    132 \n    133         self._fit(transformers)\n    134 \n    135         if self.out_array is not None:\n--> 136             self._predict(transformers, self.scorer is not None)\n        self._predict = <bound method SubLearner._predict of <mlens.parallel.learner.SubLearner object>>\n        transformers = None\n        self.scorer = make_scorer(accuracy_score)\n    137 \n    138         o = IndexedEstimator(estimator=self.estimator,\n    139                              name=self.name_index,\n    140                              index=self.index,\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/learner.py in _predict(self=<mlens.parallel.learner.SubLearner object>, transformers=None, score_preds=True)\n    200 \n    201         self.pred_time_ = time() - t0\n    202 \n    203         # Assign predictions to matrix\n    204         assign_predictions(self.out_array, predictions,\n--> 205                            self.out_index, self.output_columns, n)\n        self.out_index = (0, 50)\n        self.output_columns = 0\n        n = 500\n    206 \n    207         # Score predictions if applicable\n    208         if score_preds:\n    209             self.score_ = score_predictions(\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/mlens/parallel/_base_functions.py in assign_predictions(pred=array([[0., 0., 0., 0.],\n       [0., 0., 0., 0.]...0., 0.],\n       [0., 0., 0., 0.]], dtype=float32), p=array([[1, 1, 1, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [0, 0, 1, 1, 0],\n       [1, 0, 0, 0, 1]]), tei=(0, 50), col=0, n=500)\n    210             idx = slice(tei[0] - r, tei[1] - r)\n    211 \n    212         if len(p.shape) == 1:\n    213             pred[idx, col] = p\n    214         else:\n--> 215             pred[(idx, slice(col, col + p.shape[1]))] = p\n        pred = array([[0., 0., 0., 0.],\n       [0., 0., 0., 0.]...0., 0.],\n       [0., 0., 0., 0.]], dtype=float32)\n        idx = slice(0, 50, None)\n        col = 0\n        p.shape = (50, 5)\n        p = array([[1, 1, 1, 1, 1],\n       [0, 1, 0, 0, 0],\n...\n       [0, 0, 1, 1, 0],\n       [1, 0, 0, 0, 1]])\n    216 \n    217 \n    218 def score_predictions(y, p, scorer, name, inst_name):\n    219     \"\"\"Try-Except wrapper around Learner scoring\"\"\"\n\nValueError: could not broadcast input array from shape (50,5) into shape (50,4)\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "dataset = load_breast_cancer()\n",
    "X, Y = make_multilabel_classification(n_samples=1000)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=42)\n",
    "ensemble.fit(X_train, y_train)\n",
    "predictions = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for clf in classifiers_single:\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     predictions = clf.predict(X_test)\n",
    "#     print(clf)\n",
    "#     print(accuracy_score(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fit data:\\n%r\" % ensemble.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
